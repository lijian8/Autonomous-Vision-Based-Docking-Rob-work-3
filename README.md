# Autonomous-Vision-Based-Docking-Rob-work-3

This Repository belongs to my MSc thesis

This repository includes:

## 1. Software and Hardware Configuration

![sw_hw](https://cloud.githubusercontent.com/assets/11946010/19621300/25f3fa5e-988f-11e6-8cfc-5378ab6ce7e7.JPG)


## 2. SLAM 

	1.1. Set the initial configuration inside the map
		
	1.2. Put the marker where the docking platform is placed inside the Robotics Lab
		
	1.3. Set the position and orientation
		
## 3. Docking with Laser Scanner

	Check the capability of the laser scanner for docking of Rob@work 3
	
## 4. Docking with Vision sensor (compare the sampling period of ROS time and real time [s])

- IP camera ( stream provided with  Xperia Phone and embed live via IP address )
	
- USB camera

	![image_proc](https://cloud.githubusercontent.com/assets/11946010/20687965/ed2c6d26-b5be-11e6-96de-a36bc998ca42.JPG)
	
## 5. Q-learning approach
	Discretized grid for the docking area
	
![virtual_grid](https://cloud.githubusercontent.com/assets/11946010/19621381/cefaf458-9890-11e6-8204-dea11a74b263.JPG)

## 6. GUI 

	Developed in Qt creator
*/	
![gui](https://cloud.githubusercontent.com/assets/11946010/19621354/4367c1a0-9890-11e6-8450-332ba0fbb305.jpg)
*/
